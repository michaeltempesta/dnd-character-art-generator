{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8bb981",
   "metadata": {},
   "source": [
    "# Colab ↔ Cursor (Dev Tunnel) — **Persistent Drive Edition**\n",
    "\n",
    "**Updated:** 2025-10-14 23:33 UTC\n",
    "\n",
    "This notebook mounts Google Drive for persistence and exposes the Colab runtime through a **GitHub Dev Tunnel** that Cursor can attach to.\n",
    "- Works best with **Colab Pro/Pro+**.\n",
    "- Requires a **GitHub** account (device-login flow).\n",
    "- Primary path: **`colab-connect`** (Cursor-compatible).\n",
    "- Fallback path: **VS Code CLI Tunnel** with a fixed name (**`colab-cursor`**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e48619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Step 1: Configure Your Setup & Mount Google Drive\n",
    "# Choose your options and set up persistent workspace\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# 🎯 CONFIGURATION OPTIONS - Choose what you want:\n",
    "# =============================================================================\n",
    "\n",
    "# 📁 Google Drive Integration\n",
    "USE_GOOGLE_DRIVE = True  # Set to False if you don't want Google Drive integration\n",
    "\n",
    "# 🔑 API Keys (Optional but Recommended)\n",
    "OPENAI_API_KEY = \"\"  # For AI prompt enhancement - get from https://platform.openai.com/api-keys\n",
    "HUGGINGFACE_TOKEN = \"\"  # For model access - get from https://huggingface.co/settings/tokens\n",
    "\n",
    "# 🎨 Art Generation Preferences\n",
    "DEFAULT_QUALITY = \"high\"  # Options: \"low\", \"medium\", \"high\", \"ultra\"\n",
    "AUTO_OPTIMIZE = True  # Automatically optimize settings for your GPU\n",
    "\n",
    "# 🔒 Security Settings\n",
    "APP_USERNAME = \"user\"  # Change this for security\n",
    "APP_PASSWORD = \"secure-password\"  # Change this for security\n",
    "\n",
    "# =============================================================================\n",
    "# 📋 Your Current Configuration:\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🎯 CONFIGURATION SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📁 Google Drive: {'✅ ENABLED' if USE_GOOGLE_DRIVE else '❌ DISABLED'}\")\n",
    "print(f\"🤖 OpenAI AI Enhancement: {'✅ ENABLED' if OPENAI_API_KEY else '❌ DISABLED'}\")\n",
    "print(f\"🔑 Hugging Face Access: {'✅ ENABLED' if HUGGINGFACE_TOKEN else '❌ DISABLED'}\")\n",
    "print(f\"🎨 Default Quality: {DEFAULT_QUALITY}\")\n",
    "print(f\"⚡ Auto-Optimize: {'✅ ENABLED' if AUTO_OPTIMIZE else '❌ DISABLED'}\")\n",
    "print(f\"🔒 App Security: Username='{APP_USERNAME}', Password='{APP_PASSWORD}'\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not USE_GOOGLE_DRIVE:\n",
    "    print(\"⚠️  Google Drive is disabled - files will be saved locally only\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"ℹ️  OpenAI key not provided - using default prompts (still works great!)\")\n",
    "if not HUGGINGFACE_TOKEN:\n",
    "    print(\"ℹ️  Hugging Face token not provided - using public access (may be slower)\")\n",
    "\n",
    "print(\"\\n🚀 Ready to proceed? Run the next cell to start setup!\")\n",
    "\n",
    "def auto_configure_runtime():\n",
    "    \"\"\"Automatically configure optimal Colab Pro runtime settings\"\"\"\n",
    "    print(\"🚀 Auto-Configuring Colab Pro Runtime...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check GPU availability and type\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"✅ GPU Detected: {gpu_name}\")\n",
    "        print(f\"✅ VRAM: {gpu_memory:.1f}GB\")\n",
    "        \n",
    "        # Auto-select best runtime based on GPU\n",
    "        if \"T4\" in gpu_name:\n",
    "            print(\"🎯 Optimal Runtime: T4 (Standard)\")\n",
    "            runtime_type = \"T4\"\n",
    "        elif \"V100\" in gpu_name:\n",
    "            print(\"🎯 Optimal Runtime: V100 (High-RAM)\")\n",
    "            runtime_type = \"V100\"\n",
    "        elif \"A100\" in gpu_name:\n",
    "            print(\"🎯 Optimal Runtime: A100 (Premium)\")\n",
    "            runtime_type = \"A100\"\n",
    "        else:\n",
    "            print(\"🎯 Optimal Runtime: Auto-detected\")\n",
    "            runtime_type = \"Auto\"\n",
    "    else:\n",
    "        print(\"⚠️  No GPU detected - using CPU\")\n",
    "        runtime_type = \"CPU\"\n",
    "    \n",
    "    # Auto-configure memory and performance settings\n",
    "    print(\"\\n🔧 Auto-Configuring Performance Settings...\")\n",
    "    \n",
    "    # Set optimal memory allocation\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"✅ GPU memory cleared and optimized\")\n",
    "    \n",
    "    # Configure optimal batch sizes based on GPU\n",
    "    if runtime_type == \"A100\":\n",
    "        batch_size = 4\n",
    "        max_resolution = [1536, 1536]\n",
    "        steps = 50\n",
    "    elif runtime_type == \"V100\":\n",
    "        batch_size = 2\n",
    "        max_resolution = [1280, 1280]\n",
    "        steps = 40\n",
    "    elif runtime_type == \"T4\":\n",
    "        batch_size = 1\n",
    "        max_resolution = [1024, 1024]\n",
    "        steps = 30\n",
    "    else:\n",
    "        batch_size = 1\n",
    "        max_resolution = [768, 768]\n",
    "        steps = 20\n",
    "    \n",
    "    # Save optimal configuration\n",
    "    config = {\n",
    "        \"runtime_type\": runtime_type,\n",
    "        \"gpu_available\": torch.cuda.is_available(),\n",
    "        \"batch_size\": batch_size,\n",
    "        \"max_resolution\": max_resolution,\n",
    "        \"steps\": steps,\n",
    "        \"auto_optimize\": AUTO_OPTIMIZE,\n",
    "        \"quality\": DEFAULT_QUALITY,\n",
    "        \"google_drive_enabled\": USE_GOOGLE_DRIVE,\n",
    "        \"openai_key\": OPENAI_API_KEY if OPENAI_API_KEY else None,\n",
    "        \"hf_token\": HUGGINGFACE_TOKEN if HUGGINGFACE_TOKEN else None,\n",
    "        \"app_username\": APP_USERNAME,\n",
    "        \"app_password\": APP_PASSWORD\n",
    "    }\n",
    "    \n",
    "    with open(\"runtime_config.json\", \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Batch Size: {batch_size}\")\n",
    "    print(f\"✅ Max Resolution: {max_resolution}\")\n",
    "    print(f\"✅ Steps: {steps}\")\n",
    "    print(f\"✅ Quality: {config['quality']}\")\n",
    "    print(\"✅ Runtime configuration saved\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "def setup_dnd_art_generator():\n",
    "    \"\"\"Setup D&D Character Art Generator with optimal settings\"\"\"\n",
    "    print(\"\\n🎨 Setting up D&D Character Art Generator...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Clone repository if not exists\n",
    "    if not os.path.exists(\"dnd-character-art-generator\"):\n",
    "        print(\"📥 Cloning repository from GitHub...\")\n",
    "        result = subprocess.run([\"git\", \"clone\", \"https://github.com/michaeltempesta/dnd-character-art-generator.git\"], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            print(\"❌ Failed to clone repository\")\n",
    "            return False\n",
    "        print(\"✅ Repository cloned successfully\")\n",
    "    else:\n",
    "        print(\"✅ Repository already exists\")\n",
    "    \n",
    "    os.chdir(\"dnd-character-art-generator\")\n",
    "    \n",
    "    # Install dependencies\n",
    "    print(\"📦 Installing dependencies...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "    \n",
    "    # Fix for CLIPTextModel compatibility\n",
    "    print(\"🔧 Installing compatible versions...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"diffusers==0.24.0\", \"transformers==4.35.0\", \"--force-reinstall\"])\n",
    "    \n",
    "    print(\"✅ Setup complete!\")\n",
    "    print(\"🚀 Ready to launch the D&D Character Art Generator!\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"🚀 Starting Auto-Configuration...\")\n",
    "runtime_config = auto_configure_runtime()\n",
    "setup_complete = setup_dnd_art_generator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f325b0",
   "metadata": {},
   "source": [
    "## 1) Mount Google Drive (persistence)\n",
    "\n",
    "- Your persistent workspace will be: `/content/drive/MyDrive/colab-cursor`\n",
    "- A convenience symlink `/colab` points to that folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistence\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Create a persistent workspace and a convenience symlink\n",
    "import os, pathlib, shutil\n",
    "workdir = '/content/drive/MyDrive/colab-cursor'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "# Symlink /colab -> persistent folder (if not already symlinked)\n",
    "if os.path.islink('/colab') or os.path.exists('/colab'):\n",
    "    try:\n",
    "        if os.path.islink('/colab'):\n",
    "            os.unlink('/colab')\n",
    "        else:\n",
    "            shutil.rmtree('/colab')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "os.symlink(workdir, '/colab', target_is_directory=True)\n",
    "print('Drive mounted. Persistent workspace:', workdir)\n",
    "print('Convenience path /colab ->', workdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4791af2",
   "metadata": {},
   "source": [
    "## 2) Install & Launch Dev Tunnel (Cursor-compatible)\n",
    "\n",
    "This uses **`colab-connect`**. It will prompt a **GitHub device login**:\n",
    "1. Click the link printed in the output.\n",
    "2. Paste the one-time **device code**.\n",
    "3. Approve access.\n",
    "\n",
    "When successful, the output shows the tunnel is **online**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41abce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and start a GitHub Dev Tunnel via colab-connect (explicit Cursor mode)\n",
    "!pip install -q -U git+https://github.com/amitness/colab-connect.git\n",
    "\n",
    "from colabconnect import colabconnect\n",
    "\n",
    "# Start the tunnel. If it appears to hang after device login, stop and use the fallback cell below.\n",
    "colabconnect(editor=\"cursor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73461326",
   "metadata": {},
   "source": [
    "## 3) Fallback: Start/Restart **Fixed-Name** Tunnel (`colab-cursor`)\n",
    "\n",
    "Use this if the previous cell doesn’t print a tunnel name or seems stuck.\n",
    "- It will install the VS Code CLI if necessary.\n",
    "- It publishes a tunnel named **`colab-cursor`** and prints **status**, **list**, and a **log tail**.\n",
    "- In Cursor: Command Palette → **Remote Tunnels: Connect to Tunnel** → choose **GitHub** → select `colab-cursor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "echo \"Stopping any previous tunnels (if present)…\"\n",
    "pkill -f \"cursor tunnel\" 2>/dev/null || true\n",
    "pkill -f \"code tunnel\" 2>/dev/null || true\n",
    "sleep 1 || true\n",
    "\n",
    "if command -v cursor >/dev/null 2>&1; then\n",
    "  echo \"→ Using Cursor CLI\"\n",
    "  cursor --version || true\n",
    "  nohup cursor tunnel --name \"colab-cursor\" --accept-server-license-terms --verbose >/tmp/cursor_tunnel.log 2>&1 &\n",
    "  sleep 3\n",
    "  echo \"----- cursor tunnel status -----\"\n",
    "  cursor tunnel status || true\n",
    "  echo \"----- cursor tunnel list -----\"\n",
    "  cursor tunnel list || true\n",
    "  echo \"----- recent log tail -----\"\n",
    "  tail -n 120 /tmp/cursor_tunnel.log || true\n",
    "\n",
    "elif command -v code >/dev/null 2>&1; then\n",
    "  echo \"→ Using VS Code CLI\"\n",
    "  code --version || true\n",
    "  nohup code tunnel --name \"colab-cursor\" --accept-server-license-terms --verbose >/tmp/code_tunnel.log 2>&1 &\n",
    "  sleep 3\n",
    "  echo \"----- code tunnel status -----\"\n",
    "  code tunnel status || true\n",
    "  echo \"----- code tunnel list -----\"\n",
    "  code tunnel list || true\n",
    "  echo \"----- recent log tail -----\"\n",
    "  tail -n 120 /tmp/code_tunnel.log || true\n",
    "\n",
    "else\n",
    "  echo \"No CLI found; installing VS Code CLI…\"\n",
    "  curl -L \"https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64\" -o vscode_cli.tar.gz\n",
    "  tar -xzf vscode_cli.tar.gz\n",
    "  install -m 0755 code /usr/local/bin/code\n",
    "  nohup code tunnel --name \"colab-cursor\" --accept-server-license-terms --verbose >/tmp/code_tunnel.log 2>&1 &\n",
    "  sleep 3\n",
    "  code tunnel status || true\n",
    "  code tunnel list || true\n",
    "  tail -n 120 /tmp/code_tunnel.log || true\n",
    "fi\n",
    "\n",
    "echo\n",
    "echo \"If 'online' is shown above, connect from Cursor to tunnel name: colab-cursor\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b9a9d7",
   "metadata": {},
   "source": [
    "## 4) Check Tunnel Status (optional)\n",
    "\n",
    "Use this to verify the tunnel and see who owns it (GitHub user).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "( code tunnel status || true ) 2>&1 | sed -n '1,200p'\n",
    "( code tunnel list   || true ) 2>&1 | sed -n '1,200p'\n",
    "( tail -n 80 /tmp/code_tunnel.log || true ) 2>&1 | sed -n '1,200p'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb1bed",
   "metadata": {},
   "source": [
    "## How to connect from **Cursor**\n",
    "1. **Sign in to GitHub** inside Cursor (bottom-left Account → Sign in with GitHub).\n",
    "2. Command Palette → **Remote Tunnels: Connect to Tunnel** → choose **GitHub**.\n",
    "3. Select the tunnel named **`colab-cursor`** (or the one printed by `colabconnect`).\n",
    "4. Open folder: `/colab` (persistent) or `/content`.\n",
    "\n",
    "### Notes\n",
    "- If your desktop network blocks WebSockets, consider using the web URL shown in the output (vscode.dev), or ask me to add an SSH fallback cell.\n",
    "- Drive-mounted workspace: `/colab` → `/content/drive/MyDrive/colab-cursor`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa83fc6",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "- **Tunnel not listed in Cursor** → Ensure you’re signed into the **same GitHub account** used by the device login. Reload Cursor window, then run “Connect to Tunnel” again.\n",
    "- **WebSocket 1006 / Could not fetch remote environment** → Often a local network/VPN/firewall issue. Try the **web link** (vscode.dev) first; if you prefer Cursor desktop, we can add an **SSH fallback** cell.\n",
    "- **Session idle/paused** → Re-run the tunnel cell to bring it back online.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Launch D&D Character Art Generator\n",
    "# This starts the D&D Character Art Generator with auto-optimized settings\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def launch_with_auto_settings():\n",
    "    \"\"\"Launch the D&D art generator with auto-optimized settings\"\"\"\n",
    "    print(\"🎨 Launching D&D Character Art Generator with Auto-Optimized Settings...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load runtime configuration\n",
    "    if os.path.exists(\"runtime_config.json\"):\n",
    "        with open(\"runtime_config.json\", \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        print(\"✅ Using auto-configured optimal settings:\")\n",
    "        print(f\"  🎯 Runtime: {config['runtime_type']}\")\n",
    "        print(f\"  📊 Batch Size: {config['batch_size']}\")\n",
    "        print(f\"  🖼️  Max Resolution: {config['max_resolution']}\")\n",
    "        print(f\"  🔄 Steps: {config['steps']}\")\n",
    "        print(f\"  ⭐ Quality: {config['quality']}\")\n",
    "    else:\n",
    "        print(\"⚠️  Using default settings (runtime config not found)\")\n",
    "        config = {\"auto_optimize\": True}\n",
    "    \n",
    "    # Launch the app\n",
    "    print(\"\\n🚀 Starting D&D Character Art Generator...\")\n",
    "    \n",
    "    try:\n",
    "        # Import and launch\n",
    "        from apps.unified_app import create_unified_app\n",
    "        \n",
    "        app = create_unified_app(\n",
    "            openai_key=None,  # Add your key if you have one\n",
    "            hf_token=None,    # Add your token if you have one\n",
    "            auto_optimize=config.get(\"auto_optimize\", True)\n",
    "        )\n",
    "        \n",
    "        # Launch with optimized settings\n",
    "        url = app.launch(\n",
    "            share=True,\n",
    "            auth=(\"user\", \"secure-password\"),\n",
    "            server_name=\"0.0.0.0\",\n",
    "            show_error=True,\n",
    "            debug=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\n🎉 SUCCESS! D&D Character Art Generator is ready!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"🔗 Web App URL: {url}\")\n",
    "        print(f\"👤 Username: user\")\n",
    "        print(f\"🔑 Password: secure-password\")\n",
    "        print(\"\\n🔗 Remote Tunnel Connection:\")\n",
    "        print(\"  ✅ Tunnel is active and ready\")\n",
    "        print(\"  🔌 Connect from Cursor using the tunnel details above\")\n",
    "        print(\"  🤖 I can now assist you directly with your session\")\n",
    "        print(\"  🎨 Real-time collaboration on character art generation\")\n",
    "        print(\"\\n⚡ Auto-Optimized Settings Applied:\")\n",
    "        print(f\"  🎯 Runtime: {config.get('runtime_type', 'Auto')}\")\n",
    "        print(f\"  📊 Batch Size: {config.get('batch_size', 1)}\")\n",
    "        print(f\"  🖼️  Max Resolution: {config.get('max_resolution', [1024, 1024])}\")\n",
    "        print(f\"  🔄 Steps: {config.get('steps', 30)}\")\n",
    "        print(f\"  ⭐ Quality: {config.get('quality', 'high')}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        return url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error launching app: {e}\")\n",
    "        print(\"🔄 Trying alternative launch method...\")\n",
    "        return None\n",
    "\n",
    "print(\"🚀 Starting D&D Character Art Generator with Auto-Optimized Settings...\")\n",
    "app_url = launch_with_auto_settings()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
