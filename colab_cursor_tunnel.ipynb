{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8bb981",
   "metadata": {},
   "source": [
    "# üîó Colab Pro ‚Üî Cursor Remote Tunnel (Unified Edition)\n",
    "**Connect your Colab Pro session to Cursor for real-time AI assistance**\n",
    "\n",
    "**Updated:** 2025-10-14 23:33 UTC\n",
    "\n",
    "This notebook provides multiple approaches to connect Google Colab to Cursor:\n",
    "- **Primary**: `colab-connect` (Cursor-specific, most reliable)\n",
    "- **Fallback**: VS Code CLI Tunnel with fixed name\n",
    "- **Alternative**: Browser-based VS Code server\n",
    "- **Built-in**: Use Colab's native features\n",
    "\n",
    "## üéØ **What This Gives You**\n",
    "- **Real-time collaboration** with AI assistant\n",
    "- **Direct code editing** and debugging in your Colab session\n",
    "- **Live assistance** with D&D character art generation\n",
    "- **Seamless workflow** between Colab and Cursor\n",
    "- **Persistent workspace** with Google Drive integration\n",
    "\n",
    "## üìã **Step-by-Step Instructions**\n",
    "\n",
    "### **Step 1: Run This Notebook**\n",
    "1. **Click \"Runtime\" ‚Üí \"Run all\"** in Colab Pro\n",
    "2. **Wait for setup** (2-3 minutes)\n",
    "3. **Follow the authentication steps** when prompted\n",
    "\n",
    "### **Step 2: Connect from Cursor**\n",
    "1. **Open Cursor** on your local machine\n",
    "2. **Go to Remote Tunnels** (or Remote SSH)\n",
    "3. **Use the connection details** provided by this notebook\n",
    "4. **Click \"Connect\"** to establish the tunnel\n",
    "\n",
    "### **Step 3: Start Collaborating**\n",
    "- **I can now assist you directly** in your Colab session\n",
    "- **Real-time debugging** and code help\n",
    "- **Live guidance** for D&D character art generation\n",
    "\n",
    "üöÄ **Ready to connect? Run the next cell!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8932a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Step 1: Configure Your Setup & Mount Google Drive\n",
    "# Choose your options and set up persistent workspace\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# üéØ CONFIGURATION OPTIONS - Choose what you want:\n",
    "# =============================================================================\n",
    "\n",
    "# üìÅ Google Drive Integration\n",
    "USE_GOOGLE_DRIVE = True  # Set to False if you don't want Google Drive integration\n",
    "\n",
    "# üîë API Keys (Optional but Recommended)\n",
    "OPENAI_API_KEY = \"\"  # For AI prompt enhancement - get from https://platform.openai.com/api-keys\n",
    "HUGGINGFACE_TOKEN = \"\"  # For model access - get from https://huggingface.co/settings/tokens\n",
    "\n",
    "# üé® Art Generation Preferences\n",
    "DEFAULT_QUALITY = \"high\"  # Options: \"low\", \"medium\", \"high\", \"ultra\"\n",
    "AUTO_OPTIMIZE = True  # Automatically optimize settings for your GPU\n",
    "\n",
    "# üîí Security Settings\n",
    "APP_USERNAME = \"user\"  # Change this for security\n",
    "APP_PASSWORD = \"secure-password\"  # Change this for security\n",
    "\n",
    "# =============================================================================\n",
    "# üìã Your Current Configuration:\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üéØ CONFIGURATION SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìÅ Google Drive: {'‚úÖ ENABLED' if USE_GOOGLE_DRIVE else '‚ùå DISABLED'}\")\n",
    "print(f\"ü§ñ OpenAI AI Enhancement: {'‚úÖ ENABLED' if OPENAI_API_KEY else '‚ùå DISABLED'}\")\n",
    "print(f\"üîë Hugging Face Access: {'‚úÖ ENABLED' if HUGGINGFACE_TOKEN else '‚ùå DISABLED'}\")\n",
    "print(f\"üé® Default Quality: {DEFAULT_QUALITY}\")\n",
    "print(f\"‚ö° Auto-Optimize: {'‚úÖ ENABLED' if AUTO_OPTIMIZE else '‚ùå DISABLED'}\")\n",
    "print(f\"üîí App Security: Username='{APP_USERNAME}', Password='{APP_PASSWORD}'\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not USE_GOOGLE_DRIVE:\n",
    "    print(\"‚ö†Ô∏è  Google Drive is disabled - files will be saved locally only\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"‚ÑπÔ∏è  OpenAI key not provided - using default prompts (still works great!)\")\n",
    "if not HUGGINGFACE_TOKEN:\n",
    "    print(\"‚ÑπÔ∏è  Hugging Face token not provided - using public access (may be slower)\")\n",
    "\n",
    "print(\"\\nüöÄ Ready to proceed? Run the next cell to start setup!\")\n",
    "\n",
    "def auto_configure_runtime():\n",
    "    \"\"\"Automatically configure optimal Colab Pro runtime settings\"\"\"\n",
    "    print(\"üöÄ Auto-Configuring Colab Pro Runtime...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check GPU availability and type\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"‚úÖ GPU Detected: {gpu_name}\")\n",
    "        print(f\"‚úÖ VRAM: {gpu_memory:.1f}GB\")\n",
    "        \n",
    "        # Auto-select best runtime based on GPU\n",
    "        if \"T4\" in gpu_name:\n",
    "            print(\"üéØ Optimal Runtime: T4 (Standard)\")\n",
    "            runtime_type = \"T4\"\n",
    "        elif \"V100\" in gpu_name:\n",
    "            print(\"üéØ Optimal Runtime: V100 (High-RAM)\")\n",
    "            runtime_type = \"V100\"\n",
    "        elif \"A100\" in gpu_name:\n",
    "            print(\"üéØ Optimal Runtime: A100 (Premium)\")\n",
    "            runtime_type = \"A100\"\n",
    "        else:\n",
    "            print(\"üéØ Optimal Runtime: Auto-detected\")\n",
    "            runtime_type = \"Auto\"\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No GPU detected - using CPU\")\n",
    "        runtime_type = \"CPU\"\n",
    "    \n",
    "    # Auto-configure memory and performance settings\n",
    "    print(\"\\nüîß Auto-Configuring Performance Settings...\")\n",
    "    \n",
    "    # Set optimal memory allocation\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"‚úÖ GPU memory cleared and optimized\")\n",
    "    \n",
    "    # Configure optimal batch sizes based on GPU\n",
    "    if runtime_type == \"A100\":\n",
    "        batch_size = 4\n",
    "        max_resolution = [1536, 1536]\n",
    "        steps = 50\n",
    "    elif runtime_type == \"V100\":\n",
    "        batch_size = 2\n",
    "        max_resolution = [1280, 1280]\n",
    "        steps = 40\n",
    "    elif runtime_type == \"T4\":\n",
    "        batch_size = 1\n",
    "        max_resolution = [1024, 1024]\n",
    "        steps = 30\n",
    "    else:\n",
    "        batch_size = 1\n",
    "        max_resolution = [768, 768]\n",
    "        steps = 20\n",
    "    \n",
    "    # Save optimal configuration\n",
    "    config = {\n",
    "        \"runtime_type\": runtime_type,\n",
    "        \"gpu_available\": torch.cuda.is_available(),\n",
    "        \"batch_size\": batch_size,\n",
    "        \"max_resolution\": max_resolution,\n",
    "        \"steps\": steps,\n",
    "        \"auto_optimize\": AUTO_OPTIMIZE,\n",
    "        \"quality\": DEFAULT_QUALITY,\n",
    "        \"google_drive_enabled\": USE_GOOGLE_DRIVE,\n",
    "        \"openai_key\": OPENAI_API_KEY if OPENAI_API_KEY else None,\n",
    "        \"hf_token\": HUGGINGFACE_TOKEN if HUGGINGFACE_TOKEN else None,\n",
    "        \"app_username\": APP_USERNAME,\n",
    "        \"app_password\": APP_PASSWORD\n",
    "    }\n",
    "    \n",
    "    with open(\"runtime_config.json\", \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Batch Size: {batch_size}\")\n",
    "    print(f\"‚úÖ Max Resolution: {max_resolution}\")\n",
    "    print(f\"‚úÖ Steps: {steps}\")\n",
    "    print(f\"‚úÖ Quality: {config['quality']}\")\n",
    "    print(\"‚úÖ Runtime configuration saved\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "def setup_dnd_art_generator():\n",
    "    \"\"\"Setup D&D Character Art Generator with optimal settings\"\"\"\n",
    "    print(\"\\nüé® Setting up D&D Character Art Generator...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Clone repository if not exists\n",
    "    if not os.path.exists(\"dnd-character-art-generator\"):\n",
    "        print(\"üì• Cloning repository from GitHub...\")\n",
    "        result = subprocess.run([\"git\", \"clone\", \"https://github.com/michaeltempesta/dnd-character-art-generator.git\"], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            print(\"‚ùå Failed to clone repository\")\n",
    "            return False\n",
    "        print(\"‚úÖ Repository cloned successfully\")\n",
    "    else:\n",
    "        print(\"‚úÖ Repository already exists\")\n",
    "    \n",
    "    os.chdir(\"dnd-character-art-generator\")\n",
    "    \n",
    "    # Install dependencies\n",
    "    print(\"üì¶ Installing dependencies...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "    \n",
    "    # Fix for CLIPTextModel compatibility\n",
    "    print(\"üîß Installing compatible versions...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"diffusers==0.24.0\", \"transformers==4.35.0\", \"--force-reinstall\"])\n",
    "    \n",
    "    print(\"‚úÖ Setup complete!\")\n",
    "    print(\"üöÄ Ready to launch the D&D Character Art Generator!\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"üöÄ Starting Auto-Configuration...\")\n",
    "runtime_config = auto_configure_runtime()\n",
    "setup_complete = setup_dnd_art_generator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f325b0",
   "metadata": {},
   "source": [
    "## 1) Mount Google Drive (persistence)\n",
    "\n",
    "- Your persistent workspace will be: `/content/drive/MyDrive/colab-cursor`\n",
    "- A convenience symlink `/colab` points to that folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistence\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Create a persistent workspace and a convenience symlink\n",
    "import os, pathlib, shutil\n",
    "workdir = '/content/drive/MyDrive/colab-cursor'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "# Symlink /colab -> persistent folder (if not already symlinked)\n",
    "if os.path.islink('/colab') or os.path.exists('/colab'):\n",
    "    try:\n",
    "        if os.path.islink('/colab'):\n",
    "            os.unlink('/colab')\n",
    "        else:\n",
    "            shutil.rmtree('/colab')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "os.symlink(workdir, '/colab', target_is_directory=True)\n",
    "print('Drive mounted. Persistent workspace:', workdir)\n",
    "print('Convenience path /colab ->', workdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4791af2",
   "metadata": {},
   "source": [
    "## 2) Install & Launch Dev Tunnel (Cursor-compatible)\n",
    "\n",
    "This uses **`colab-connect`**. It will prompt a **GitHub device login**:\n",
    "1. Click the link printed in the output.\n",
    "2. Paste the one-time **device code**.\n",
    "3. Approve access.\n",
    "\n",
    "When successful, the output shows the tunnel is **online**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41abce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and start a GitHub Dev Tunnel via colab-connect (explicit Cursor mode)\n",
    "!pip install -q -U git+https://github.com/amitness/colab-connect.git\n",
    "\n",
    "from colabconnect import colabconnect\n",
    "\n",
    "# Start the tunnel. If it appears to hang after device login, stop and use the fallback cell below.\n",
    "colabconnect(editor=\"cursor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73461326",
   "metadata": {},
   "source": [
    "## 3) Fallback: Start/Restart **Fixed-Name** Tunnel (`colab-cursor`)\n",
    "\n",
    "Use this if the previous cell doesn‚Äôt print a tunnel name or seems stuck.\n",
    "- It will install the VS Code CLI if necessary.\n",
    "- It publishes a tunnel named **`colab-cursor`** and prints **status**, **list**, and a **log tail**.\n",
    "- In Cursor: Command Palette ‚Üí **Remote Tunnels: Connect to Tunnel** ‚Üí choose **GitHub** ‚Üí select `colab-cursor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "echo \"Stopping any previous tunnels (if present)‚Ä¶\"\n",
    "pkill -f \"cursor tunnel\" 2>/dev/null || true\n",
    "pkill -f \"code tunnel\" 2>/dev/null || true\n",
    "sleep 1 || true\n",
    "\n",
    "if command -v cursor >/dev/null 2>&1; then\n",
    "  echo \"‚Üí Using Cursor CLI\"\n",
    "  cursor --version || true\n",
    "  nohup cursor tunnel --name \"colab-cursor\" --accept-server-license-terms --verbose >/tmp/cursor_tunnel.log 2>&1 &\n",
    "  sleep 3\n",
    "  echo \"----- cursor tunnel status -----\"\n",
    "  cursor tunnel status || true\n",
    "  echo \"----- cursor tunnel list -----\"\n",
    "  cursor tunnel list || true\n",
    "  echo \"----- recent log tail -----\"\n",
    "  tail -n 120 /tmp/cursor_tunnel.log || true\n",
    "\n",
    "elif command -v code >/dev/null 2>&1; then\n",
    "  echo \"‚Üí Using VS Code CLI\"\n",
    "  code --version || true\n",
    "  nohup code tunnel --name \"colab-cursor\" --accept-server-license-terms --verbose >/tmp/code_tunnel.log 2>&1 &\n",
    "  sleep 3\n",
    "  echo \"----- code tunnel status -----\"\n",
    "  code tunnel status || true\n",
    "  echo \"----- code tunnel list -----\"\n",
    "  code tunnel list || true\n",
    "  echo \"----- recent log tail -----\"\n",
    "  tail -n 120 /tmp/code_tunnel.log || true\n",
    "\n",
    "else\n",
    "  echo \"No CLI found; installing VS Code CLI‚Ä¶\"\n",
    "  curl -L \"https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64\" -o vscode_cli.tar.gz\n",
    "  tar -xzf vscode_cli.tar.gz\n",
    "  install -m 0755 code /usr/local/bin/code\n",
    "  nohup code tunnel --name \"colab-cursor\" --accept-server-license-terms --verbose >/tmp/code_tunnel.log 2>&1 &\n",
    "  sleep 3\n",
    "  code tunnel status || true\n",
    "  code tunnel list || true\n",
    "  tail -n 120 /tmp/code_tunnel.log || true\n",
    "fi\n",
    "\n",
    "echo\n",
    "echo \"If 'online' is shown above, connect from Cursor to tunnel name: colab-cursor\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Launch D&D Character Art Generator\n",
    "# This starts the D&D Character Art Generator with auto-optimized settings\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def launch_with_auto_settings():\n",
    "    \"\"\"Launch the D&D art generator with auto-optimized settings\"\"\"\n",
    "    print(\"üé® Launching D&D Character Art Generator with Auto-Optimized Settings...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load runtime configuration\n",
    "    if os.path.exists(\"runtime_config.json\"):\n",
    "        with open(\"runtime_config.json\", \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        print(\"‚úÖ Using auto-configured optimal settings:\")\n",
    "        print(f\"  üéØ Runtime: {config['runtime_type']}\")\n",
    "        print(f\"  üìä Batch Size: {config['batch_size']}\")\n",
    "        print(f\"  üñºÔ∏è  Max Resolution: {config['max_resolution']}\")\n",
    "        print(f\"  üîÑ Steps: {config['steps']}\")\n",
    "        print(f\"  ‚≠ê Quality: {config['quality']}\")\n",
    "        print(f\"  ü§ñ OpenAI Key: {'‚úÖ PROVIDED' if config.get('openai_key') else '‚ùå NOT PROVIDED'}\")\n",
    "        print(f\"  üîë HF Token: {'‚úÖ PROVIDED' if config.get('hf_token') else '‚ùå NOT PROVIDED'}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Using default settings (runtime config not found)\")\n",
    "        config = {\"auto_optimize\": True}\n",
    "    \n",
    "    # Launch the app\n",
    "    print(\"\\nüöÄ Starting D&D Character Art Generator...\")\n",
    "    \n",
    "    try:\n",
    "        # Import and launch\n",
    "        from apps.unified_app import create_unified_app\n",
    "        \n",
    "        app = create_unified_app(\n",
    "            openai_key=config.get('openai_key'),  # Use configured key\n",
    "            hf_token=config.get('hf_token'),      # Use configured token\n",
    "            auto_optimize=config.get(\"auto_optimize\", True)\n",
    "        )\n",
    "        \n",
    "        # Launch with optimized settings\n",
    "        url = app.launch(\n",
    "            share=True,\n",
    "            auth=(config.get('app_username', 'user'), config.get('app_password', 'secure-password')),\n",
    "            server_name=\"0.0.0.0\",\n",
    "            show_error=True,\n",
    "            debug=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\nüéâ SUCCESS! D&D Character Art Generator is ready!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üîó Web App URL: {url}\")\n",
    "        print(f\"üë§ Username: {config.get('app_username', 'user')}\")\n",
    "        print(f\"üîë Password: {config.get('app_password', 'secure-password')}\")\n",
    "        print(\"\\nüîó Remote Tunnel Connection:\")\n",
    "        print(\"  ‚úÖ Tunnel is active and ready\")\n",
    "        print(\"  üîå Connect from Cursor using the tunnel details above\")\n",
    "        print(\"  ü§ñ I can now assist you directly with your session\")\n",
    "        print(\"  üé® Real-time collaboration on character art generation\")\n",
    "        print(\"\\n‚ö° Auto-Optimized Settings Applied:\")\n",
    "        print(f\"  üéØ Runtime: {config.get('runtime_type', 'Auto')}\")\n",
    "        print(f\"  üìä Batch Size: {config.get('batch_size', 1)}\")\n",
    "        print(f\"  üñºÔ∏è  Max Resolution: {config.get('max_resolution', [1024, 1024])}\")\n",
    "        print(f\"  üîÑ Steps: {config.get('steps', 30)}\")\n",
    "        print(f\"  ‚≠ê Quality: {config.get('quality', 'high')}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        return url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error launching app: {e}\")\n",
    "        print(\"üîÑ Trying alternative launch method...\")\n",
    "        return None\n",
    "\n",
    "print(\"üöÄ Starting D&D Character Art Generator with Auto-Optimized Settings...\")\n",
    "app_url = launch_with_auto_settings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b9a9d7",
   "metadata": {},
   "source": [
    "## 4) Check Tunnel Status (optional)\n",
    "\n",
    "Use this to verify the tunnel and see who owns it (GitHub user).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "( code tunnel status || true ) 2>&1 | sed -n '1,200p'\n",
    "( code tunnel list   || true ) 2>&1 | sed -n '1,200p'\n",
    "( tail -n 80 /tmp/code_tunnel.log || true ) 2>&1 | sed -n '1,200p'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb1bed",
   "metadata": {},
   "source": [
    "## How to connect from **Cursor**\n",
    "1. **Sign in to GitHub** inside Cursor (bottom-left Account ‚Üí Sign in with GitHub).\n",
    "2. Command Palette ‚Üí **Remote Tunnels: Connect to Tunnel** ‚Üí choose **GitHub**.\n",
    "3. Select the tunnel named **`colab-cursor`** (or the one printed by `colabconnect`).\n",
    "4. Open folder: `/colab` (persistent) or `/content`.\n",
    "\n",
    "### Notes\n",
    "- If your desktop network blocks WebSockets, consider using the web URL shown in the output (vscode.dev), or ask me to add an SSH fallback cell.\n",
    "- Drive-mounted workspace: `/colab` ‚Üí `/content/drive/MyDrive/colab-cursor`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa83fc6",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "- **Tunnel not listed in Cursor** ‚Üí Ensure you‚Äôre signed into the **same GitHub account** used by the device login. Reload Cursor window, then run ‚ÄúConnect to Tunnel‚Äù again.\n",
    "- **WebSocket 1006 / Could not fetch remote environment** ‚Üí Often a local network/VPN/firewall issue. Try the **web link** (vscode.dev) first; if you prefer Cursor desktop, we can add an **SSH fallback** cell.\n",
    "- **Session idle/paused** ‚Üí Re-run the tunnel cell to bring it back online.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
